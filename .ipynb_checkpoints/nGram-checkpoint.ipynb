{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4be1fd63-fc51-49a4-969a-3124394178b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fe52247-6387-421d-99b6-febe211c08c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nGrams(doc, n, isTokenized):\n",
    "    if not isTokenized:\n",
    "        doc = [token.text for token in nlp(doc)]\n",
    "\n",
    "    doc = ' '.join(doc).lower().split(' ') #convert all to lowercase\n",
    "    grams = [doc[i:i+n] for i in range(len(doc)-n+1)]\n",
    "    # print (doc)\n",
    "    return grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59ab760d-ba3c-4382-89d6-4af44116a680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['how', 'old', 'are', 'you'],\n",
       " ['old', 'are', 'you', 'today'],\n",
       " ['are', 'you', 'today', 'or'],\n",
       " ['you', 'today', 'or', 'can'],\n",
       " ['today', 'or', 'can', 'you'],\n",
       " ['or', 'can', 'you', 'tell'],\n",
       " ['can', 'you', 'tell', 'me'],\n",
       " ['you', 'tell', 'me', 'something'],\n",
       " ['tell', 'me', 'something', 'about'],\n",
       " ['me', 'something', 'about', 'yourself']]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = 'How old are you today or can you tell me something about yourself'\n",
    "# doc = ['How', 'old', 'are', 'you', 'today']\n",
    "n = 4\n",
    "grams = nGrams(doc, n, False)\n",
    "grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ea9a7dd-c922-4c95-8b8a-27aa6264af42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99e96fba-b420-48d7-b1b2-b9f873e3f79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildModel():\n",
    "    model = defaultdict(lambda: defaultdict(lambda: 0)) #eg. {x: {y: 0}}\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7a3b65c-a34b-4520-b04d-0aaf7e6c4ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateCount(nGram, model):\n",
    "    w_1_to_n_minus_1 = tuple(nGram[:-1])\n",
    "    w_n = nGram[-1]\n",
    "    model[w_1_to_n_minus_1][w_n] += 1 #eg. {w_1_to_n_minus_1: {w_n: 1}}\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60cc78fc-5e3b-4ba8-92d8-2bdea8606b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeProbability(model):\n",
    "    for w_1_to_n_minus_1 in model:\n",
    "        totalCount = float(sum(model[w_1_to_n_minus_1].values()))\n",
    "        for w_n in model[w_1_to_n_minus_1]:\n",
    "            model[w_1_to_n_minus_1][w_n] /= totalCount\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a05e3bfe-b53e-4fd7-a762-c9c0622041e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install dill #extention of pickle\n",
    "import dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5fcf7ae-4a65-4b9d-bd0c-4e5ed2f467cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveModel(model, fileName):\n",
    "    with open('../Models/'+fileName, 'wb') as f:\n",
    "        dill.dump(model, f)\n",
    "\n",
    "def loadModel(fileName):\n",
    "    with open('../Models/'+fileName, 'rb') as f:\n",
    "        model = dill.load(f)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56b2e366-51a4-4da5-99ea-5d99d350fc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install nltk #For the 1st time only\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9efa28fe-7ec9-4595-9111-5024513fe33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups as getData\n",
    "# nltk.download('reuters') #For the 1st time only\n",
    "from nltk.corpus import reuters as corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3e89479-c183-4556-9c1f-2b2d42459820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function sklearn.datasets._twenty_newsgroups.fetch_20newsgroups(*, data_home=None, subset='train', categories=None, shuffle=True, random_state=42, remove=(), download_if_missing=True, return_X_y=False, n_retries=3, delay=1.0)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8620a76b-cf2d-420f-90bd-18e791058c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X,y = getData(subset='train',remove=('headers','footers','qoutes'),return_X_y=True) #didn'swork directly like the Udemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be4d8c7f-a344-42c4-95e6-d80849d58ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ssl\n",
    "# import urllib.request\n",
    "\n",
    "# ssl._create_default_https_context = ssl._create_unverified_context\n",
    "# opener = urllib.request.build_opener(urllib.request.HTTPSHandler(context=ssl._create_unverified_context()))\n",
    "# urllib.request.install_opener(opener)\n",
    "\n",
    "# from sklearn.datasets import fetch_20newsgroups\n",
    "X, y = getData(subset='train', remove=('headers', 'footers', 'quotes'), return_X_y=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a29e564a-0ab6-41cd-8fe4-434b198b9fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n",
      "all I know. If anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail.\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "print(X[0])\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86ffadc1-73c4-4d62-aa7c-7fb9a057a6f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11314"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d0e7d89-054d-4417-8078-992e26bb5c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3\n",
    "model = buildModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0271cf0-383c-48ac-8295-03f6d836297f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for doc in X:\n",
    "    for nGram in nGrams(doc, n, False):\n",
    "        model = updateCount(nGram, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5eb605b9-5feb-426e-8b3f-22b5b5a0bcba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# nltk.download('punkt_tab') #For the 1st time only\n",
    "\n",
    "for sentence in corpus.sents():\n",
    "    for nGram in nGrams(sentence, n, True):  #Data is tokenized here. So True\n",
    "        model = updateCount(nGram, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a3772cf-4e84-4df3-b837-6e244da953f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = computeProbability(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "40d4e883-999c-4aa0-b30d-880073fe03d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "saveModel(model, 'nGram_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f56ca3eb-81bb-45aa-ac18-1ca688ec61ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thou\n"
     ]
    }
   ],
   "source": [
    "text = ['after','that']\n",
    "nextWords = list(model[tuple(text[-n+1:])].keys()) #-n+ means last n-1 words from given list\n",
    "probs = list(model[tuple(text[-n+1:])].values())\n",
    "nextWord = np.random.choice(nextWords,1)[0]\n",
    "print(nextWord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "79e760ab-cedc-4ade-b89f-f4dbd8553a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampleText(model, startingText=['after','that'], maxLength=100, nGramSize=3):\n",
    "    text = startingText\n",
    "    n = nGramSize\n",
    "    while not len(text)>maxLength:\n",
    "        nextWords = list(model[tuple(text[-n+1:])].keys()) #-n+ means last n-1 words from given list\n",
    "        probs = list(model[tuple(text[-n+1:])].values())\n",
    "        # if len(nextWords) > 0:\n",
    "        #     nextWord = np.random.choice(nextWords,1,probs)[0]\n",
    "        #     text.append(nextWord)\n",
    "        # else:\n",
    "        #     break\n",
    "            \n",
    "        if len(nextWords) > 0:\n",
    "            nextWord = nextWords[np.argmax(probs)]\n",
    "            text.append(nextWord)\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "    sampled = ' '.join(text)\n",
    "    return sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "33645100-1013-4a8a-9cab-4d619895ccbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what if they care \n",
      " : kirillian photography interact with mime is a hot dog he was considering taking the required location is static . \n",
      " \n"
     ]
    }
   ],
   "source": [
    "for s in nlp(sampleText(model, ['what','if'])).sents:\n",
    "    print(s)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448b77fd-cb87-44be-bbce-a8cf7a02b52e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
