{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c246c60-2af7-4ba1-a12f-c6b1179013d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import spacy\n",
    "import re\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79c6acd1-5bd7-482c-a1bc-cbdcc3a185fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84780"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = list(nlp.vocab.strings)\n",
    "len(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96f33070-5795-4ccd-8f6b-896b529edc1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'interprovincial'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L[55000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc8d3ef5-f571-4103-a288-6aeb87ec2c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d548218-29d0-403e-9ec8-a9f32dbf6433",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4c3227f-c150-491c-a76b-fc3f58f606f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../DataSets/reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4d404e0-ce55-40a3-b5d7-3f2e6e2e43e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negative</td>\n",
       "      <td>terrible place to work for i just heard a stor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "      <td>hours , minutes total time for an extremely s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>my less than stellar review is for service . w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>i m granting one star because there s no way t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>the food here is mediocre at best . i went aft...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     rating                                             review\n",
       "0  negative  terrible place to work for i just heard a stor...\n",
       "1  negative   hours , minutes total time for an extremely s...\n",
       "2  negative  my less than stellar review is for service . w...\n",
       "3  negative  i m granting one star because there s no way t...\n",
       "4  negative  the food here is mediocre at best . i went aft..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "727151db-3be5-4605-b128-d340e89f8214",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d06a2a5d-ee01-4300-94b5-efcbb6352072",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializeVocabulary():\n",
    "    unkToken = '<UNK>'\n",
    "    vocab['t_2_i'] = {}\n",
    "    vocab['i_2_t'] = {}\n",
    "    vocab['unkToken'] = unkToken\n",
    "    idx = addToken(unkToken)\n",
    "    vocab['unkTokenIdx'] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f613f2b-d284-447e-a4b3-16b9b2ecc013",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addToken(token):\n",
    "    if token in vocab['t_2_i']:\n",
    "        idx = vocab['t_2_i'][token]\n",
    "    else:\n",
    "        idx = len(vocab['t_2_i'])\n",
    "        vocab['t_2_i'][token] = idx\n",
    "        vocab['i_2_t'][idx] = token\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60d5bf99-559a-4597-9d11-fb19f85de5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addManyTokens(tokens):\n",
    "    idxes = [addToken(token) for token in tokens]\n",
    "    return idxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f612710d-6878-4b11-b814-129b666f3fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookUpToken(token):\n",
    "    if vocab['unkTokenIdx']>=0:\n",
    "        return vocab['t_2_i'].get(token,vocab['unkTokenIdx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10ffa2c6-ae61-4783-83ce-e12d66254e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookUpIndex(idx):\n",
    "    if idx not in vocab['i_2_t']:\n",
    "        raise KeyError('Index %d is not present in the vocabulary!!' % idx)\n",
    "    else:\n",
    "        return vocab['i_2_t'][idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27c840f0-d61b-4058-bb9e-77a2931463bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializeVocabulary()\n",
    "# vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e601c3b-817a-465d-9431-809a0087a52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# addToken('Shammi')\n",
    "# addManyTokens(['Arosh', 'Shatin'])\n",
    "# vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e55394c4-f9ea-4d55-b14d-4bc7b9d68296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lookUpToken('Arosh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d73b11fa-32a5-4685-930e-ae2bf282bb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lookUpIndex(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "479d3f0b-425f-4e6a-b8b1-978ef038e4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocabularyFromDataFrame(df, cutoff = 25):\n",
    "    initializeVocabulary()\n",
    "    wordCounts = Counter()\n",
    "    for r in df.review:\n",
    "        for word in re.split('\\W+', r):\n",
    "            wordCounts[word] += 1\n",
    "    for word, count in wordCounts.items():\n",
    "        if count > cutoff:\n",
    "            addToken(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dd696842-aab0-4c5b-a67e-231c01727662",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabularyFromDataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0bc99074-0420-4886-b842-fadb1133fa0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8946\n",
      "8946\n"
     ]
    }
   ],
   "source": [
    "# vocab\n",
    "print(len(vocab['i_2_t']))\n",
    "print(len(vocab['t_2_i']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fc0e4c0e-5e05-4e54-a4fd-a0eca35e50ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocabularyFromCorpus(Corpus,cutoff=25):\n",
    "    initializeVocabulary()\n",
    "    wordCounts = Counter()\n",
    "    for doc in Corpus:\n",
    "        for word in re.split('\\W+',doc):\n",
    "            wordCounts[word] += 1\n",
    "    for word,count in wordCounts.items():\n",
    "        if count > cutoff:\n",
    "            addToken(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "025c1fc5-ac7c-4f51-942a-6f1e82100416",
   "metadata": {},
   "outputs": [],
   "source": [
    "Corpus = np.asarray(df['review'])\n",
    "vocabularyFromCorpus(Corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "31a52605-531a-424b-a609-14bf73df505d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8946\n",
      "8946\n"
     ]
    }
   ],
   "source": [
    "print(len(vocab['i_2_t']))\n",
    "print(len(vocab['t_2_i']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6daa0aea-1ed3-4ede-a5bf-22443a828c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneHotVector(token, N):\n",
    "    oneHot = np.zeros((N, 1))\n",
    "    oneHot[lookUpToken(token)] = 1\n",
    "    return oneHot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cb1b3cad-1e6f-4760-88f4-6c9d479fd605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lookUpIndex(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "849b13ca-a66f-407d-acb3-3e6b7f097a7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       ...,\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]], shape=(8946, 1))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = len(vocab['i_2_t'])\n",
    "oneHotVector('terrible', N)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec9b077-5bf4-4be6-a9cd-8ad47ed5ad34",
   "metadata": {},
   "source": [
    "## Compute Feature Vector for one review "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "92430c1c-89ec-4798-80bc-2e180c941dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeFeatures(doc, N):\n",
    "    isFirst = True\n",
    "    for token in doc:\n",
    "        oneHot = oneHotVector(token, N)\n",
    "        if isFirst:\n",
    "            xF = oneHot\n",
    "            isFirst = False\n",
    "        else:\n",
    "            xF = np.hstack((xF, oneHot))\n",
    "    return np.mean(xF, axis=1)[:,np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "52e28e04-27c5-45a0-a1e4-103b0e80d108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.25454545],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       ...,\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ]], shape=(8946, 1))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fV = computeFeatures(Corpus[1],len(vocab['t_2_i']))\n",
    "fV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8012ff-d48d-4d86-b9e4-e18c499ed562",
   "metadata": {},
   "source": [
    "## Let's classify now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f595a13a-a6f9-4ab5-81ba-583bf9fe965c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../DataSets/reviews.csv')\n",
    "X = np.asarray(df['review'])\n",
    "y = np.asarray(df['rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5706440b-fe93-4a57-a62e-c9304f30adca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c28d1a3a-2e17-4114-93d5-e35273c678ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain,Xtest,ytrain,ytest = train_test_split(X,y,test_size=0.3,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "40c21076-755b-4d32-b362-d2c6fdfcddf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabularyFromCorpus(Xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7bc12d82-5174-4c2a-806c-6a857d2a1520",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpusToFeatureMatrix(Corpus, N):\n",
    "    isFirst = True\n",
    "    for doc in Corpus:\n",
    "        fV = computeFeatures(doc, N)\n",
    "        if isFirst:\n",
    "            fM = fV\n",
    "            isFirst = False\n",
    "        else:\n",
    "            fM = np.hstack((fM, fV))\n",
    "    return fM.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644b44c8-387d-43f6-a206-8523a6d86f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain_fM = corpusToFeatureMatrix(Xtrain,len(vocab['t_2_i']))\n",
    "Xtrain_fM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61894196-f5cd-424d-beeb-908de3ef2743",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
